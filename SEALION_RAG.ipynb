{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9634edda-a930-4a40-941a-ffdab9c53bf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T13:20:17.854572Z",
     "iopub.status.busy": "2025-07-21T13:20:17.854275Z",
     "iopub.status.idle": "2025-07-21T13:20:25.492657Z",
     "shell.execute_reply": "2025-07-21T13:20:25.492077Z",
     "shell.execute_reply.started": "2025-07-21T13:20:17.854554Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install -U langchain-community\n",
    "%pip install pypdf\n",
    "%pip install chromadb\n",
    "%pip install sentence-transformers\n",
    "%pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3196870d-1881-42c4-b2be-c5416a1b37ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T16:11:39.248157Z",
     "iopub.status.busy": "2025-07-21T16:11:39.247977Z",
     "iopub.status.idle": "2025-07-21T16:11:46.935685Z",
     "shell.execute_reply": "2025-07-21T16:11:46.935173Z",
     "shell.execute_reply.started": "2025-07-21T16:11:39.248140Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 16:11:44.424621: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-21 16:11:44.438308: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753114304.456404    8589 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753114304.462003    8589 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-21 16:11:44.479684: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import logging\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain.vectorstores.chroma import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bad07ac-e802-4732-96ea-310dbf9249fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T16:11:46.936891Z",
     "iopub.status.busy": "2025-07-21T16:11:46.936344Z",
     "iopub.status.idle": "2025-07-21T16:12:09.434839Z",
     "shell.execute_reply": "2025-07-21T16:12:09.434310Z",
     "shell.execute_reply.started": "2025-07-21T16:11:46.936869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA device in use: Tesla T4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "2025-07-21 16:11:48,959 [INFO] We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9d78ff4beca4514a1dbc12ee944d3de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "2025-07-21 16:12:06,737 [INFO] Pipeline created.\n",
      "/tmp/ipykernel_8589/1459776502.py:30: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-base\")\n",
      "2025-07-21 16:12:07,207 [INFO] Use pytorch device_name: cuda:0\n",
      "2025-07-21 16:12:07,207 [INFO] Load pretrained SentenceTransformer: intfloat/multilingual-e5-base\n"
     ]
    }
   ],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s [%(levelname)s] %(message)s\")\n",
    "\n",
    "assert torch.cuda.is_available(), \"CUDA is not available. GPU is not being used!\"\n",
    "print(\"CUDA device in use:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "model_id = \"aisingapore/Llama-SEA-LION-v3.5-8B-R\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    device_map=\"auto\",\n",
    "    load_in_8bit=True,          # Enable 8-bit quantization\n",
    "    torch_dtype=torch.float16,\n",
    ")\n",
    "\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "\n",
    "logging.info(\"Pipeline created.\")\n",
    "\n",
    "\n",
    "DATA_PATH = \"./data/\"\n",
    "CHROMA_PATH = \"chroma\"\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"intfloat/multilingual-e5-base\")\n",
    "\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are a helpful loan officer. Use the information below to match the user's profile with suitable loan products from the brochure.\n",
    "\n",
    "Speak **in Khmer**. Use short, clear sentences. Avoid technical terms and do not over-explain. No bold or italic formatting.\n",
    "\n",
    "User Information:\n",
    "- Location: {location}\n",
    "- Monthly Income: ${monthly_income}\n",
    "- Business Age: {business_age_months} months\n",
    "- Collateral: {collateral}\n",
    "- Existing Loans: {existing_loans}\n",
    "\n",
    "Loan Brochure:\n",
    "{context}\n",
    "\n",
    "Instructions:\n",
    "1. List the loan products the user qualifies for.\n",
    "2. Briefly explain why they qualify.\n",
    "3. If they don’t qualify, explain why.\n",
    "4. Keep the answer short and easy to understand.\n",
    "5. Do not answer anything you dont have the context to.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_documents():\n",
    "  \"\"\"\n",
    "  Load PDF documents from the specified directory using PyPDFDirectoryLoader.\n",
    "\n",
    "  Returns:\n",
    "      List[Document]: Loaded PDF documents with metadata including source file and page number.\n",
    "  \"\"\"\n",
    "  from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "\n",
    "  # Load PDF documents\n",
    "  document_loader = PyPDFDirectoryLoader(DATA_PATH)\n",
    "  documents = document_loader.load()\n",
    "\n",
    "  # Ensure metadata contains 'source' and 'page'\n",
    "  for i, doc in enumerate(documents[:5]):  # Just print first 5 for debug\n",
    "      print(f\"Doc {i + 1}:\")\n",
    "      print(f\"  Source: {doc.metadata.get('source')}\")\n",
    "      print(f\"  Page: {doc.metadata.get('page')}\")\n",
    "\n",
    "  return documents\n",
    "\n",
    "\n",
    "def split_text(documents: list[Document]):\n",
    "  \"\"\"\n",
    "  Split the text of the loaded documents into smaller chunks using RecursiveCharacterTextSplitter.\n",
    "\n",
    "  Args:\n",
    "      documents (list[Document]): List of Document objects to be split.\n",
    "\n",
    "  Returns:\n",
    "      List of Document objects: Documents with text split into smaller chunks.\n",
    "  \"\"\"\n",
    "  text_splitter = RecursiveCharacterTextSplitter(\n",
    "      chunk_size=512,\n",
    "      chunk_overlap=100,\n",
    "      length_function=len,\n",
    "      add_start_index=True\n",
    "  )\n",
    "\n",
    "  chunks = text_splitter.split_documents(documents)\n",
    "\n",
    "  # Log chunks and metadata for debugging\n",
    "  print(f\"Split {len(documents)} documents into {len(chunks)} chunks.\")\n",
    "  for i, chunk in enumerate(chunks[:3]):  # Show a few samples\n",
    "      print(f\"Chunk {i + 1} metadata:\", chunk.metadata)\n",
    "\n",
    "  return chunks\n",
    "\n",
    "\n",
    "\n",
    "def save_to_chroma(chunks: list[Document]):\n",
    "\n",
    "  \"\"\"\n",
    "  Save the split document chunks to a Chroma vector store.\n",
    "  Args:\n",
    "      chunks (list[Document]): List of Document objects to be saved.\n",
    "\n",
    "  Returns:\n",
    "      None\n",
    "  \"\"\"\n",
    "\n",
    "  # Load existing DB or create a new one\n",
    "  if os.path.exists(CHROMA_PATH):\n",
    "      db = Chroma(\n",
    "          persist_directory=CHROMA_PATH,\n",
    "          embedding_function=embedding_model\n",
    "      )\n",
    "      db.add_documents(chunks)  # Add new documents\n",
    "      print(\"Added new documents to existing Chroma vector store.\")\n",
    "  else:\n",
    "      db = Chroma.from_documents(\n",
    "          chunks,\n",
    "          embedding_model,\n",
    "          persist_directory=CHROMA_PATH\n",
    "      )\n",
    "      print(\"Created new Chroma vector store.\")\n",
    "\n",
    "  db.persist()\n",
    "  print(f\"Saved {len(chunks)} chunks to {CHROMA_PATH}.\")\n",
    "\n",
    "def generate_data_store():\n",
    "  \"\"\"\n",
    "  Main function to generate vector database in chroma from documents.\n",
    "  Returns:\n",
    "      None\n",
    "  \"\"\"\n",
    "  documents = load_documents() # Load documents from a source\n",
    "  chunks = split_text(documents) # Split documents into manageable chunks\n",
    "  save_to_chroma(chunks) # Save the processed data to a data store\n",
    "\n",
    "def extract_entities(text: str) -> dict:\n",
    "    print(f\"[INFO] Extracting entities from text: {text}\")\n",
    "\n",
    "    ner_prompt = f\"\"\"\n",
    "    You are an information extractor. Your task is to return ONLY a valid JSON object with these keys: location, monthly_income, business_age_months, collateral, existing_loans.\n",
    "    \n",
    "    DO NOT include any explanations, introductions, or any text outside the JSON. ONLY output the JSON.\n",
    "    \n",
    "    User input:\n",
    "    {text}\n",
    "    \n",
    "    Output:\n",
    "    \"\"\"\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": ner_prompt}]\n",
    "\n",
    "    print(\"[INFO] Running SEA-LION NER prompt with thinking_mode off...\")\n",
    "    try:\n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            add_generation_prompt=True,\n",
    "            tokenize=False,\n",
    "            thinking_mode=\"off\"\n",
    "        )\n",
    "\n",
    "        output = pipeline(\n",
    "            prompt,\n",
    "            max_new_tokens=512,\n",
    "            return_full_text=False,\n",
    "            truncation=True,\n",
    "            do_sample=False,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Pipeline execution failed: {e}\")\n",
    "        return {\n",
    "            \"location\": None,\n",
    "            \"monthly_income\": None,\n",
    "            \"business_age_months\": None,\n",
    "            \"collateral\": None,\n",
    "            \"existing_loans\": None\n",
    "        }\n",
    "\n",
    "    ner_text = output[0].get(\"generated_text\", \"\").strip()\n",
    "    print(f\"[INFO] Raw NER output:\\n{ner_text}\")\n",
    "\n",
    "    entities = {\n",
    "        \"location\": None,\n",
    "        \"monthly_income\": None,\n",
    "        \"business_age_months\": None,\n",
    "        \"collateral\": None,\n",
    "        \"existing_loans\": None\n",
    "    }\n",
    "\n",
    "    \n",
    "\n",
    "    json_match = re.search(r\"\\{.*\\}\", ner_text, re.DOTALL)\n",
    "    if json_match:\n",
    "        json_str = json_match.group(0)\n",
    "        print(f\"[DEBUG] Matched JSON string: {json_str}\")\n",
    "        try:\n",
    "            parsed = json.loads(json_str)\n",
    "            for key in entities.keys():\n",
    "                if key in parsed:\n",
    "                    val = parsed[key]\n",
    "                    if key in [\"monthly_income\", \"business_age_months\"]:\n",
    "                        try:\n",
    "                            val_clean = int(re.sub(r\"[^\\d]\", \"\", str(val)))\n",
    "                            print(f\"[DEBUG] Parsed {key}: raw='{val}', cleaned={val_clean}\")\n",
    "                            val = val_clean\n",
    "                        except Exception as e:\n",
    "                            print(f\"[WARN] Failed to parse {key} value '{val}': {e}\")\n",
    "                    entities[key] = val\n",
    "                else:\n",
    "                    print(f\"[WARN] Missing key '{key}' in parsed output\")\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"[WARN] JSON decoding failed: {e}\")\n",
    "    else:\n",
    "        print(\"[WARN] No JSON object found in NER output\")\n",
    "\n",
    "    print(f\"[INFO] Extracted entities: {entities}\")\n",
    "    return entities\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ask_question(query_text: str, k: int = 3):\n",
    "    logging.info(\"Starting question processing...\")\n",
    "\n",
    "    # Extract entities from user input via SEA-LION NER\n",
    "    entities = extract_entities(query_text)\n",
    "    logging.info(f\"Extracted entities: {entities}\")\n",
    "\n",
    "    db = Chroma(\n",
    "        persist_directory=CHROMA_PATH,\n",
    "        embedding_function=embedding_model\n",
    "    )\n",
    "\n",
    "    logging.info(\"Performing semantic search...\")\n",
    "    results = db.similarity_search(query_text, k=k)\n",
    "    logging.info(f\"Retrieved {len(results)} relevant chunks.\")\n",
    "\n",
    "    context_chunks = []\n",
    "    for doc in results:\n",
    "        metadata = doc.metadata or {}\n",
    "        context_chunks.append({\n",
    "            \"filename\": os.path.basename(metadata.get(\"source\", \"unknown.pdf\")),\n",
    "            \"page\": metadata.get(\"page\", 1),\n",
    "            \"text\": doc.page_content.strip()\n",
    "        })\n",
    "\n",
    "    context_text = \"\\n\\n\".join([chunk[\"text\"] for chunk in context_chunks])\n",
    "\n",
    "    prompt = PROMPT_TEMPLATE.format(\n",
    "        location=entities.get(\"location\", \"Unknown\"),\n",
    "        monthly_income=entities.get(\"monthly_income\", \"Unknown\"),\n",
    "        business_age_months=entities.get(\"business_age_months\", \"Unknown\"),\n",
    "        collateral=entities.get(\"collateral\", \"Unknown\"),\n",
    "        existing_loans=entities.get(\"existing_loans\", \"Unknown\"),\n",
    "        context=context_text\n",
    "    ).strip()\n",
    "\n",
    "    logging.info(\"Generating response from SEA-LION pipeline...\")\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    print(\"[INFO] Prompt: \", prompt)\n",
    "    output = pipeline(\n",
    "        messages,\n",
    "        max_new_tokens=4096,\n",
    "        return_full_text=False,\n",
    "        truncation=True,\n",
    "    )\n",
    "    logging.info(\"Response generation complete.\")\n",
    "\n",
    "    print(\"[INFO] Output: \", output)\n",
    "\n",
    "    answer = output[0][\"generated_text\"].strip()\n",
    "\n",
    "    return answer, context_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b556294-ae11-4907-9f57-cdf80b565b22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T16:12:09.435907Z",
     "iopub.status.busy": "2025-07-21T16:12:09.435437Z",
     "iopub.status.idle": "2025-07-21T16:12:10.309628Z",
     "shell.execute_reply": "2025-07-21T16:12:10.309094Z",
     "shell.execute_reply.started": "2025-07-21T16:12:09.435887Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc 1:\n",
      "  Source: data/Loan Product Km.pdf\n",
      "  Page: 0\n",
      "Split 1 documents into 2 chunks.\n",
      "Chunk 1 metadata: {'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-07-21T23:11:01+07:00', 'author': 'NHEM DARAYUT', 'moddate': '2025-07-21T23:11:01+07:00', 'source': 'data/Loan Product Km.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'start_index': 0}\n",
      "Chunk 2 metadata: {'producer': 'Microsoft® Word 2019', 'creator': 'Microsoft® Word 2019', 'creationdate': '2025-07-21T23:11:01+07:00', 'author': 'NHEM DARAYUT', 'moddate': '2025-07-21T23:11:01+07:00', 'source': 'data/Loan Product Km.pdf', 'total_pages': 1, 'page': 0, 'page_label': '1', 'start_index': 417}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8589/1459776502.py:121: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  db = Chroma(\n",
      "2025-07-21 16:12:09,987 [INFO] Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added new documents to existing Chroma vector store.\n",
      "Saved 2 chunks to chroma.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8589/1459776502.py:135: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  db.persist()\n"
     ]
    }
   ],
   "source": [
    "generate_data_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13b7d24-198b-425a-ad4d-8b64a15b9a91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-21T16:12:10.312420Z",
     "iopub.status.busy": "2025-07-21T16:12:10.312119Z",
     "iopub.status.idle": "2025-07-21T16:14:10.779430Z",
     "shell.execute_reply": "2025-07-21T16:14:10.778914Z",
     "shell.execute_reply.started": "2025-07-21T16:12:10.312402Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 16:12:10,314 [INFO] Starting question processing...\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Extracting entities from text: អាជីវកម្មរបស់ខ្ញុំស្ថិតនៅភ្នំពេញ ដំណើរការមកបាន ១៤ ខែ មានចំណូល ៩០០ ដុល្លារក្នុងមួយខែ។ ខ្ញុំមានម៉ូតូជាវត្ថុបញ្ចាំ និងមិនមានប្រាក់កម្ចីណាមួយស្រាប់។\n",
      "[INFO] Running SEA-LION NER prompt with thinking_mode off...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 16:12:19,146 [INFO] Extracted entities: {'location': 'ភ្នំពេញ', 'monthly_income': 900, 'business_age_months': 14, 'collateral': 'ម៉ូតូ', 'existing_loans': 'គ្មាន'}\n",
      "2025-07-21 16:12:19,150 [INFO] Performing semantic search...\n",
      "2025-07-21 16:12:19,179 [INFO] Retrieved 2 relevant chunks.\n",
      "2025-07-21 16:12:19,180 [INFO] Generating response from SEA-LION pipeline...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Raw NER output:\n",
      "{\n",
      "  \"location\": \"ភ្នំពេញ\",\n",
      "  \"monthly_income\": 900,\n",
      "  \"business_age_months\": 14,\n",
      "  \"collateral\": \"ម៉ូតូ\",\n",
      "  \"existing_loans\": \"គ្មាន\"\n",
      "}\n",
      "[DEBUG] Matched JSON string: {\n",
      "  \"location\": \"ភ្នំពេញ\",\n",
      "  \"monthly_income\": 900,\n",
      "  \"business_age_months\": 14,\n",
      "  \"collateral\": \"ម៉ូតូ\",\n",
      "  \"existing_loans\": \"គ្មាន\"\n",
      "}\n",
      "[DEBUG] Parsed monthly_income: raw='900', cleaned=900\n",
      "[DEBUG] Parsed business_age_months: raw='14', cleaned=14\n",
      "[INFO] Extracted entities: {'location': 'ភ្នំពេញ', 'monthly_income': 900, 'business_age_months': 14, 'collateral': 'ម៉ូតូ', 'existing_loans': 'គ្មាន'}\n",
      "[INFO] Prompt:  You are a helpful loan officer. Use the information below to match the user's profile with suitable loan products from the brochure.\n",
      "\n",
      "Speak **in Khmer**. Use short, clear sentences. Avoid technical terms and do not over-explain. No bold or italic formatting.\n",
      "\n",
      "User Information:\n",
      "- Location: ភ្នំពេញ\n",
      "- Monthly Income: $900\n",
      "- Business Age: 14 months\n",
      "- Collateral: ម៉ូតូ\n",
      "- Existing Loans: គ្មាន\n",
      "\n",
      "Loan Brochure:\n",
      "• ទីាំងខែលអាចដាក់ពាកយាន៖ ប្ររប្់ញែតតប្រកុង \n",
      "ផលិតផលឥណទាន៖ Equipment Backed Loan \n",
      "• ប្រតូវមានមា  ុីនឬយានជំនិិះជាប្ទប្ញ្ញី \n",
      "• អាជីវកមមប្រតូវានចុិះប្្ជី \n",
      "• អាយុកាលអាជីវកមម៖ 18+ ខែ \n",
      "• ប្រាក់ចំណ ូ ល៖ $1,200+/ខែ\n",
      "\n",
      "ផលិតផលឥណទាន៖ MSME Growth Loan \n",
      "• ប្រាក់ចំណ ូ លអប្បប្រមា៖ $800 កនុងមួយខែ \n",
      "• អាយុកាលអាជីវកមម៖ 12 ខែ \n",
      "• ប្ទប្ញ្ញីអាចទទួលយក៖ ម ូតូ, ឡាន, អចលនវតថុ \n",
      "• ចំនួនប្រាក់ឥណទាន៖ $1,000 - $10,000 \n",
      "• អប្រាការប្រាក់៖ 1.5% កនុងមួយខែ \n",
      "• ទីាំងខែលអាចដាក់ពាកយាន៖ ភ្នំញេញ, ញ ៀមរាប្ \n",
      "ផលិតផលឥណទាន៖ Nano Startup Loan \n",
      "• ប្រាក់ចំណ ូ លអប្បប្រមា៖ $300 កនុងមួយខែ \n",
      "• អាយុកាលអាជីវកមម៖ 6 ខែ \n",
      "• មិនចំាច់មានប្ទប្ញ្ញី \n",
      "• ចំនួនប្រាក់ឥណទាន៖ $100 - $1,000 \n",
      "• ទីាំងខែលអាចដាក់ពាកយាន៖ ប្ររប្់ញែតតប្រកុង \n",
      "ផលិតផលឥណទាន៖ Equipment Backed Loan\n",
      "\n",
      "Instructions:\n",
      "1. List the loan products the user qualifies for.\n",
      "2. Briefly explain why they qualify.\n",
      "3. If they don’t qualify, explain why.\n",
      "4. Keep the answer short and easy to understand.\n",
      "5. Do not answer anything you dont have the context to.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-21 16:14:10,776 [INFO] Response generation complete.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Output:  [{'generated_text': \"Okay, let's start by looking at the user's information. They are located in Phnom Penh, have a monthly income of $900, their business is 14 months old, and they have a motorcycle as collateral. They don't have any existing loans.\\n\\nNow, checking the loan brochure. There are three products: Equipment Backed Loan, MSME Growth Loan, and Nano Startup Loan.\\n\\nFirst, the Equipment Backed Loan. The requirements are unclear from the provided info, but since the user has collateral (motorcycle), they might qualify. However, the brochure doesn't specify income requirements for this product, so I can't confirm for sure.\\n\\nNext, the MSME Growth Loan. It requires a monthly income of at least $800, which the user has ($900). The business needs to be 12 months old, which it is (14 months). They can use motorcycle as collateral. The loan amount is $1,000-$10,000. This seems to fit. The interest rate is 1.5% monthly, but the user's income is sufficient, so they qualify.\\n\\nThe Nano Startup Loan has a minimum income of $300, which the user exceeds. But the business must be 6 months old, which it isn't (14 months). So they don't qualify for this.\\n\\nSo, the user qualifies for the Equipment Backed Loan and MSME Growth Loan. They don't qualify for the Nano Startup Loan due to business age.\\n</think>\\n\\nអ្នកអាចទទួលបានឥណទានបីប្រភេទ៖\\n\\n1. ឥណទានដែលគាំទ្រដោយសម្បត្តិ (Equipment Backed Loan)\\n   - អ្នកមានម៉ូតូជាបញ្ញីដែលអាចប្រើជាបញ្ញីដាក់បញ្ញីបាន។\\n\\n2. ឥណទានសម្រាប់ការលូតលាស់អាជីវកម្ម MSME\\n   - ប្រាក់ចំណូលខែរបស់អ្នកគឺ $900 ជាង $800 ដែលតម្រូវការ។ អាជីវកម្មរបស់អ្នកមានអាយុ 14 ខែ គឺលើសពី 12 ខែដែលតម្រូវការ។\\n\\n3. ឥណទានសម្រាប់អ្នកចាប់ផ្តើមបច្ចេកវិជ្ជា Nano Startup\\n   - អ្នកមិនអាចទទួលបានឥណទានប្រភេទនេះទេ ព្រោះអាជីវកម្មរបស់អ្នកមានអាយុតិចជាង 6 ខែ។\"}]\n",
      "\n",
      "Generated Answer:\n",
      " Okay, let's start by looking at the user's information. They are located in Phnom Penh, have a monthly income of $900, their business is 14 months old, and they have a motorcycle as collateral. They don't have any existing loans.\n",
      "\n",
      "Now, checking the loan brochure. There are three products: Equipment Backed Loan, MSME Growth Loan, and Nano Startup Loan.\n",
      "\n",
      "First, the Equipment Backed Loan. The requirements are unclear from the provided info, but since the user has collateral (motorcycle), they might qualify. However, the brochure doesn't specify income requirements for this product, so I can't confirm for sure.\n",
      "\n",
      "Next, the MSME Growth Loan. It requires a monthly income of at least $800, which the user has ($900). The business needs to be 12 months old, which it is (14 months). They can use motorcycle as collateral. The loan amount is $1,000-$10,000. This seems to fit. The interest rate is 1.5% monthly, but the user's income is sufficient, so they qualify.\n",
      "\n",
      "The Nano Startup Loan has a minimum income of $300, which the user exceeds. But the business must be 6 months old, which it isn't (14 months). So they don't qualify for this.\n",
      "\n",
      "So, the user qualifies for the Equipment Backed Loan and MSME Growth Loan. They don't qualify for the Nano Startup Loan due to business age.\n",
      "</think>\n",
      "\n",
      "អ្នកអាចទទួលបានឥណទានបីប្រភេទ៖\n",
      "\n",
      "1. ឥណទានដែលគាំទ្រដោយសម្បត្តិ (Equipment Backed Loan)\n",
      "   - អ្នកមានម៉ូតូជាបញ្ញីដែលអាចប្រើជាបញ្ញីដាក់បញ្ញីបាន។\n",
      "\n",
      "2. ឥណទានសម្រាប់ការលូតលាស់អាជីវកម្ម MSME\n",
      "   - ប្រាក់ចំណូលខែរបស់អ្នកគឺ $900 ជាង $800 ដែលតម្រូវការ។ អាជីវកម្មរបស់អ្នកមានអាយុ 14 ខែ គឺលើសពី 12 ខែដែលតម្រូវការ។\n",
      "\n",
      "3. ឥណទានសម្រាប់អ្នកចាប់ផ្តើមបច្ចេកវិជ្ជា Nano Startup\n",
      "   - អ្នកមិនអាចទទួលបានឥណទានប្រភេទនេះទេ ព្រោះអាជីវកម្មរបស់អ្នកមានអាយុតិចជាង 6 ខែ។\n"
     ]
    }
   ],
   "source": [
    "# Run your query\n",
    "example_query = \"អាជីវកម្មរបស់ខ្ញុំស្ថិតនៅភ្នំពេញ ដំណើរការមកបាន ១៤ ខែ មានចំណូល ៩០០ ដុល្លារក្នុងមួយខែ។ ខ្ញុំមានម៉ូតូជាវត្ថុបញ្ចាំ និងមិនមានប្រាក់កម្ចីណាមួយស្រាប់។\"\n",
    "\n",
    "answer, context = ask_question(example_query, 3)\n",
    "\n",
    "print(\"\\nGenerated Answer:\\n\", answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850707fc-da10-49e4-a301-1d24ffb6b7b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
